# Horse Racing Prediction API (PMU)

Ce projet implÃ©mente une chaÃ®ne de traitement complÃ¨te pour l'analyse et la prÃ©diction des courses de trot. Il a Ã©tÃ© refactorisÃ© pour suivre les standards de production modernes, avec une sÃ©paration stricte entre le **Backend** (Logique mÃ©tier, ETL, ML) et le **Frontend** (Interface utilisateur).

L'architecture est modulaire :
- **Backend** : FastAPI, SQLAlchemy/Postgres, XGBoost (Python lourd).
- **Frontend** : Streamlit (Python lÃ©ger), consommation via API REST.

## ğŸ“š Documentation Technique

L'ensemble de la documentation dÃ©taillÃ©e se trouve dans le dossier [`doc/`](./doc/).

**GÃ©nÃ©ral & Projet :**
*   [`00_introduction.md`](./doc/00_introduction.md) : Contexte et vue d'ensemble.
*   [`01_cahier_des_charges.md`](./doc/01_cahier_des_charges.md) : Objectifs et pÃ©rimÃ¨tre fonctionnel.
*   [`03_planning.md`](./doc/03_planning.md) : Roadmap et suivi des phases.

**Data & Backend :**
*   [`02_architecture_bdd.md`](./doc/02_architecture_bdd.md) : ModÃ¨le de donnÃ©es (SQL) et dictionnaire.
*   [`04_ingestion.md`](./doc/04_ingestion.md) : StratÃ©gie ETL et sources de donnÃ©es.
*   [`05_preparation_donnees_ml.md`](./doc/05_preparation_donnees_ml.md) : Feature Engineering et prÃ©paration pour le ML.
*   [`06_api_backend.md`](./doc/06_api_backend.md) : Documentation technique de l'API et des endpoints.

**Interface :**
*   [`07_frontend.md`](./doc/07_frontend.md) : Architecture de l'application Streamlit.

---

## ğŸ— Architecture Technique

Le projet est divisÃ© en deux sous-systÃ¨mes distincts pour assurer une meilleure maintenabilitÃ© et faciliter la conteneurisation (Docker).

### Arborescence du projet

```text
horse-racing-prediction/
â”œâ”€â”€ backend/                # COEUR DU SYSTÃˆME
â”‚   â”œâ”€â”€ .env                # Variables d'environnement (BDD)
â”‚   â”œâ”€â”€ .venv/              # Environnement virtuel dÃ©diÃ© Backend
â”‚   â”œâ”€â”€ requirements.txt    # DÃ©pendances (FastAPI, XGBoost, Pandas...)
â”‚   â”œâ”€â”€ data/               # Stockage des modÃ¨les (.pkl) et exports
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ cli/            # Scripts d'administration (ETL)
â”‚       â”œâ”€â”€ api/            # API REST (FastAPI)
â”‚       â”œâ”€â”€ ml/             # Pipeline Machine Learning
â”‚       â””â”€â”€ core/           # Config & Database
â”‚
â”œâ”€â”€ frontend/               # INTERFACE UTILISATEUR
â”‚   â”œâ”€â”€ .venv/              # Environnement virtuel dÃ©diÃ© Frontend
â”‚   â”œâ”€â”€ requirements.txt    # DÃ©pendances lÃ©gÃ¨res (Streamlit, Requests)
â”‚   â”œâ”€â”€ main.py             # Entrypoint Dashboard
â”‚   â””â”€â”€ api_client.py       # Connecteur vers le Backend
â”‚
â”œâ”€â”€ doc/                    # DOCUMENTATION DU PROJET
â”‚   â”œâ”€â”€ 00_introduction.md
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ 07_frontend.md
â”‚
â””â”€â”€ README.md               # Ce fichier
```

---

## âš™ï¸ Installation

Ce projet nÃ©cessite **deux terminaux** et **deux environnements virtuels** distincts.

### 1. Configuration du Backend

Ouvrez un terminal et naviguez vers le dossier `backend` :

```bash
cd backend
python -m venv .venv

# Activation (Windows)
.venv\Scripts\activate
# Activation (Mac/Linux)
source .venv/bin/activate

# Installation des dÃ©pendances lourdes
pip install -r requirements.txt
```

**Configuration de la BDD :**
CrÃ©ez un fichier `.env` dans le dossier `backend/` :

```ini
DB_URL=postgresql://USER:PASSWORD@HOST:PORT/DATABASE_NAME
```

### 2. Configuration du Frontend

Ouvrez un **nouveau terminal** et naviguez vers le dossier `frontend` :

```bash
cd frontend
python -m venv .venv

# Activation
# Windows: .venv\Scripts\activate
# Mac/Linux: source .venv/bin/activate

# Installation des dÃ©pendances lÃ©gÃ¨res
pip install -r requirements.txt
```

---

## ğŸš€ Utilisation

Voici le guide complet, Ã©tape par Ã©tape, pour lancer ce projet de zÃ©ro en utilisant Docker.

### 1. DÃ©marrer l'Infrastructure

Ouvrez votre terminal Ã  la racine du projet et exÃ©cutez :

```bash
docker compose up --build

```

* **Attendez** que le dÃ©filement des logs se stabilise et que vous voyiez des messages indiquant que la Base de donnÃ©es, le Backend et le Frontend sont prÃªts (ex: `Uvicorn running`, `database system is ready to accept connections`).
* **Gardez ce terminal ouvert.** Il affiche les journaux (logs) du serveur.

---

### 2. Peupler la Base de DonnÃ©es (Crucial)

La base de donnÃ©es Docker dÃ©marre vide. Nous devons injecter les donnÃ©es des courses d'aujourd'hui.

1. Ouvrez un **Second Terminal**.
2. ExÃ©cutez le script ETL **Ã  l'intÃ©rieur** du conteneur backend actif (ajustez la date Ã  aujourd'hui, **28122025**) :

```bash
docker exec -it pmu_backend python -m src.cli.etl --date 28122025 --type all

```

* **Attendez** de voir le message : `INFO | ORCHESTRATOR | All jobs completed.`

---

### 3. Utiliser l'Application

Tout est maintenant opÃ©rationnel.

* **Frontend (Dashboard) :** [http://localhost:8501](https://www.google.com/search?q=http://localhost:8501)
* *Action :* SÃ©lectionnez **2025/12/28** dans la barre latÃ©rale. VÃ©rifiez la prÃ©sence des recommandations "Sniper" en haut de page.


* **Backend (Documentation API) :** [http://localhost:8000/docs](https://www.google.com/search?q=http://localhost:8000/docs)
* *Action :* Utilisez `GET /` pour vÃ©rifier si le `ml_engine` est bien chargÃ©.

**2. EntraÃ®nement du modÃ¨le (Machine Learning)**
Le script rÃ©cupÃ¨re les donnÃ©es SQL, gÃ©nÃ¨re les features et sauvegarde le modÃ¨le dans `backend/ml/`.
```bash
python -m src.ml.trainer
```

**3. DÃ©marrer le serveur API**
```bash
# L'API sera accessible sur http://localhost:8000
uvicorn src.api.main:app --reload
```

### B. Terminal 2 : Frontend (Dashboard)

Assurez-vous d'Ãªtre dans le dossier `frontend/` avec le venv activÃ©. Assurez-vous que l'API Backend tourne dans l'autre terminal.

```bash
# Le dashboard s'ouvrira sur http://localhost:8501
streamlit run main.py
```

---

## ğŸ—º Roadmap & Avancement

**Phase 1 : Socle de DonnÃ©es (TerminÃ©)**
- [x] Architecture BDD PostgreSQL.
- [x] Pipeline ETL robuste avec gestion d'erreurs.

**Phase 2 : API & Exposition (TerminÃ©)**
- [x] Backend FastAPI structurÃ©.
- [x] Pattern Repository & Schemas Pydantic.

**Phase 3 : Machine Learning (TerminÃ©)**
- [x] Feature Engineering avancÃ©.
- [x] Pipeline d'entraÃ®nement automatisÃ© (`src/ml/trainer.py`).
- [x] IntÃ©gration du modÃ¨le dans l'API.

**Phase 4 : Interface & Architecture (En cours)**
- [x] Dashboard Frontend (Streamlit) connectÃ© Ã  l'API.
- [ ] Dockerisation (Backend Dockerfile & Frontend Dockerfile).
- [ ] Automatisation CI/CD (GitHub Actions).