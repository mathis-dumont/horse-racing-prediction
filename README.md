# üèá Turf Analytics Pro

**Turf Analytics Pro** est une solution compl√®te d'intelligence artificielle d√©di√©e √† l'analyse et √† la pr√©diction des courses hippiques (Trot).

Cette plateforme int√®gre une cha√Æne de traitement de donn√©es (ETL) performante, un moteur de Machine Learning (XGBoost) et une interface utilisateur interactive pour d√©tecter les meilleures opportunit√©s de paris (*Value Betting*) en temps r√©el.

## üìã Table des Mati√®res

- [Architecture](#-architecture)
- [Fonctionnalit√©s](#-fonctionnalit√©s)
- [Structure du Projet](#-structure-du-projet)
- [Installation & D√©marrage (Docker)](#-installation--d√©marrage-rapide-docker)
- [üîÑ Automatisation (GitHub Actions)](#-automatisation--ci-cd)
- [Installation Manuelle (D√©veloppement)](#-installation-manuelle-local)
- [Utilisation de la CLI](#-utilisation-de-la-cli-etl--ml)
- [Tests & Documentation](#-tests--documentation)

---

## üèó Architecture

Le projet repose sur une architecture d√©coupl√©e assurant performance et scalabilit√© :

1.  **Backend (API & Core)** :
    *   **Framework** : FastAPI.
    *   **Base de donn√©es** : PostgreSQL (H√©berg√© sur Supabase).
    *   **Moteur ML** : Pipeline Scikit-Learn / XGBoost avec calibration de probabilit√©s.
    *   **Ingestion** : Orchestrateur ETL multithread√© pour la r√©cup√©ration des donn√©es PMU (Programme, Participants, Performances, Rapports).

2.  **Frontend (UI)** :
    *   **Framework** : Streamlit.
    *   **R√¥le** : Dashboard de visualisation consommant l'API REST pour afficher les pronostics, les d√©tails des courses et les recommandations de paris ("Sniper").

3.  **DevOps** :
    *   **Conteneurisation** : Docker & Docker Compose.
    *   **CI/CD** : GitHub Actions pour l'ingestion quotidienne automatique.

---

## ‚ú® Fonctionnalit√©s

*   **Ingestion Automatis√©e** : R√©cup√©ration parall√®le des donn√©es.
*   **Algorithme "Sniper"** : Strat√©gie de *Value Betting* comparant les probabilit√©s de l'IA aux cotes r√©elles du march√©.
*   **Machine Learning Avanc√©** : Feature Engineering temporel, gestion des donn√©es manquantes et calibration (Isotonic Regression).
*   **Tableau de Bord Interactif** : Navigation par date, analyse des partants et monitoring des opportunit√©s.

---

## üìÇ Structure du Projet

```text
project-root/
‚îú‚îÄ‚îÄ .github/workflows/      # Pipelines CI/CD
‚îÇ   ‚îî‚îÄ‚îÄ daily_etl.yml       # Workflow d'ingestion journalier
‚îú‚îÄ‚îÄ backend/                # Services Backend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/            # API REST (FastAPI)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cli/            # Scripts d'administration (ETL)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/           # Configuration & Base de donn√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingestion/      # Scrapers & Parsers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ml/             # Entra√Ænement & Inf√©rence ML
‚îÇ   ‚îú‚îÄ‚îÄ data/               # Stockage des mod√®les (.pkl)
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ frontend/               # Interface Utilisateur
‚îÇ   ‚îú‚îÄ‚îÄ app.py              # Point d'entr√©e Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ doc/                    # Documentation technique
‚îî‚îÄ‚îÄ docker-compose.yml      # Orchestration des conteneurs
```

---

## üê≥ Installation & D√©marrage Rapide (Docker)

C'est la m√©thode recommand√©e pour d√©ployer l'application localement.

### 1. Configuration (Secrets)
Le projet se connecte √† une base de donn√©es persistante (Supabase).
Cr√©ez un fichier `.env` dans la racine du projet :

```ini
# ./.env
DB_URL=postgresql://USER:PASSWORD@HOST:PORT/DATABASE_NAME
```

### 2. Lancer les services
√Ä la racine du projet :

```bash
docker compose up --build -d
```
Cela d√©marre l'API Backend et le Frontend.

* **Attendez** que le d√©filement des logs se stabilise et que vous voyiez des messages indiquant que la Base de donn√©es, le Backend et le Frontend sont pr√™ts (ex: `Uvicorn running`, `database system is ready to accept connections`).
* **Gardez ce terminal ouvert.** Il affiche les journaux (logs) du serveur.

### 3. Entra√Ænement Initial (Premier Lancement)
Si c'est la premi√®re fois que vous lancez le projet et que le mod√®le (`.pkl`) n'existe pas encore, g√©n√©rez-le directement √† l'int√©rieur du conteneur :

```bash
docker exec -it pmu_backend python -m src.ml.trainer
```
*Cette commande va cr√©er le fichier mod√®le dans le conteneur, et gr√¢ce au volume configur√© (`./backend/data:/app/data`), le fichier sera sauvegard√© sur votre machine.*

---

### 3. Mise √† jour manuelle (Optionnel)
Si vous souhaitez forcer une r√©cup√©ration des donn√©es sur un certain jour :

```bash
# Exemple : R√©cup√©rer les donn√©es d'un jour (29/12/2025)
docker exec -it pmu_backend python -m src.cli.etl --date 29122025 --type all
```

### 4. Acc√®s
*   **Dashboard** : [http://localhost:8501](http://localhost:8501)
*   **API Docs** : [http://localhost:8000/docs](http://localhost:8000/docs)

---

## üîÑ Automatisation & CI/CD

Ce projet int√®gre un workflow GitHub Actions (`.github/workflows/daily_etl.yml`) pour assurer la fra√Æcheur des donn√©es sans intervention humaine.

### Fonctionnement du Workflow
*   **Fr√©quence** : Ex√©cution quotidienne automatique √† **06:00 UTC**.
*   **Logique (Fen√™tre Glissante)** : √Ä chaque ex√©cution, le script r√©cup√®re les donn√©es de **J-2 √† J (Aujourd'hui)**.
    *   *Pourquoi ?* Cela permet de r√©cup√©rer le programme du jour, mais aussi de mettre √† jour les r√©sultats et rapports d√©finitifs des courses de la veille et de l'avant-veille.
*   **D√©clenchement Manuel** : Possibilit√© de lancer le workflow manuellement depuis l'interface GitHub ("Run workflow") en sp√©cifiant une date pr√©cise si n√©cessaire.

### Configuration Requise
Pour que le workflow fonctionne sur votre fork/repository, vous devez configurer le secret suivant dans **Settings > Secrets and variables > Actions** :

| Nom du Secret | Description |
| :--- | :--- |
| `DB_URL` | La cha√Æne de connexion PostgreSQL (Supabase/Prod). |

---

## üõ† Installation Manuelle (Local)

Pour le d√©veloppement sans Docker.

### Partie 1 : Backend

1.  Configurer `backend/.env` avec votre `DB_URL`.
2.  Installer les d√©pendances :
    ```bash
    cd backend
    python -m venv .venv
    source .venv/bin/activate  # ou .venv\Scripts\activate (Windows)
    pip install -r requirements.txt
    ```

3.  **Entra√Ænement Initial (Premier Lancement)**
    Cette √©tape est **n√©cessaire la premi√®re fois** pour cr√©er le fichier mod√®le (`.pkl`) utilis√© par l'API pour les pr√©dictions :
    ```bash
    # Assurez-vous d'√™tre dans le dossier backend/
    python3 -m src.ml.trainer
    ```

4.  Lancer l'API :
    ```bash
    uvicorn src.api.main:app --reload
    ```

### Partie 2 : Frontend

Dans un nouveau terminal :
```bash
cd frontend
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
streamlit run app.py
```

---

## üíª Utilisation de la CLI (Backend)

Le backend expose des outils en ligne de commande pour g√©rer les donn√©es manuellement.

| Action | Commande (depuis `backend/`) | Description |
| :--- | :--- | :--- |
| **Ingestion (Jour)** | `python -m src.cli.etl --date JJMMAAAA --type all` | R√©cup√®re tout pour une date sp√©cifique. |
| **Ingestion (Plage)** | `python -m src.cli.etl --range DEBUT FIN --type program` | R√©cup√®re les donn√©es sur une p√©riode. |
| **Entra√Ænement ML** | `python -m src.ml.trainer` | R√©-entra√Æne le mod√®le XGBoost sur les donn√©es SQL actuelles. |

---

## üß™ Tests & Documentation

### Tests Unitaires
Les tests sont g√©r√©s par `pytest` et couvrent l'ingestion et la logique API.

```bash
cd backend
pytest
```

### Documentation Technique
D√©tails disponibles dans le dossier [`doc/`](./doc/) :
*   **Architecture BDD** : Mod√®le relationnel.
*   **API Reference** : Endpoints et sch√©mas.
*   **ML** : Feature engineering et calibration.

---

## üìÑ Licence

Ce projet est distribu√© sous licence MIT. Voir le fichier `LICENSE` pour plus d'informations.