# Projet de prÃ©diction des rÃ©sultats de courses hippiques franÃ§aises

Ce projet vise Ã  construire un systÃ¨me complet pour la collecte de donnÃ©es, l'analyse et la prÃ©diction des rÃ©sultats des courses hippiques franÃ§aises, en s'appuyant sur l'API publique du PMU.

## FonctionnalitÃ©s

*   **Collecte exhaustive** : RÃ©cupÃ©ration des Programmes (JSON 1), Participants (JSON 2), Performances dÃ©taillÃ©es/Musique (JSON 3) et Rapports (JSON 4).
*   **Ingestion performante** : Scripts optimisÃ©s utilisant le **multithreading** et l'insertion par lots (batch processing) pour gÃ©rer la volumÃ©trie importante des historiques.
*   **Orchestration** : Scripts permettant l'ingestion d'une journÃ©e complÃ¨te ou d'une plage de dates (reprise d'historique).
*   **Stockage structurÃ©** : Base de donnÃ©es PostgreSQL normalisÃ©e pour faciliter l'analyse ML.
*   **DiscrÃ©tion** : Gestion des dÃ©lais et des en-tÃªtes HTTP pour simuler un comportement humain (Stealth Mode).

---

## Structure du projet

```text
horse-racing-prediction/
â”œâ”€â”€ scripts/                # Scripts d'ingestion (ETL) et d'inspection
â”‚   â”œâ”€â”€ ingest_full_day.py       # Orchestrateur pour une journÃ©e complÃ¨te
â”‚   â”œâ”€â”€ ingest_range.py          # Orchestrateur pour une pÃ©riode (historique)
â”‚   â”œâ”€â”€ ingest_*.py              # Scripts unitaires par type de donnÃ©es (programme, perfs...)
â”‚   â””â”€â”€ inspect_*.py             # Scripts d'analyse exploratoire des JSON
â”œâ”€â”€ src/pmu_prediction/     # Code applicatif (API, ML, Core)
â”‚   â”œâ”€â”€ pmu_api/            # Client HTTP
â”‚   â”œâ”€â”€ ingestion/          # Logique mÃ©tier d'ingestion
â”‚   â”œâ”€â”€ db/                 # Connexion DB
â”‚   â””â”€â”€ ml/                 # Machine Learning (Features, Training, Predict)
â”œâ”€â”€ sql/                    # Scripts d'initialisation de la BDD
â”œâ”€â”€ doc/                    # Documentation technique et fonctionnelle
â”œâ”€â”€ tests/                  # Tests unitaires
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â””â”€â”€ README.md               # Ce fichier
```

---

## Installation

1. **Cloner le dÃ©pÃ´t et installer les dÃ©pendances :**

```bash
pip install -r requirements.txt
```

2. **Configurer l'environnement :**

CrÃ©ez un fichier `.env` Ã  la racine du projet :

```ini
DB_URL=postgresql://USER:PASSWORD@HOST:PORT/DATABASE_NAME
```

3. **Initialiser la base de donnÃ©es :**

ExÃ©cutez les scripts SQL dans l'ordre pour crÃ©er les tables et les contraintes :

1. `sql/01_schema_initial.sql`
2. `sql/02_add_constraints.sql`

---

## Utilisation

### 1. Ingestion d'une journÃ©e complÃ¨te
Pour rÃ©cupÃ©rer le programme, les participants, les performances et les rapports d'une date spÃ©cifique :

```bash
python scripts/ingest_full_day.py --date 05112025
```

### 2. Ingestion d'une pÃ©riode (Historique)
Pour rÃ©cupÃ©rer des donnÃ©es sur plusieurs jours consÃ©cutifs (ex: pour constituer le dataset d'entraÃ®nement) :

```bash
python scripts/ingest_range.py --start 01112025 --end 05112025
```

### 3. Scripts unitaires (Debugging)
Il est possible de lancer l'ingestion Ã©tape par Ã©tape :

*   **Programme** : `python scripts/ingest_programme_day.py --date DDMMYYYY`
*   **Participants** : `python scripts/ingest_participants_day.py --date DDMMYYYY`
*   **Performances** : `python scripts/ingest_performances_day.py --date DDMMYYYY`
*   **Rapports** : `python scripts/ingest_rapports_day.py --date DDMMYYYY`

---

## Documentation

Une documentation dÃ©taillÃ©e est disponible dans le dossier `doc/` :

*   **01_cahier_des_charges.md** : Objectifs et pÃ©rimÃ¨tre.
*   **02_architecture_bdd.md** : SchÃ©ma relationnel et dictionnaire des donnÃ©es.
*   **04_scripts_ingestion.md** : DÃ©tails techniques sur le pipeline ETL.

---

## ğŸ—º Roadmap & Avancement

**Ingestion des donnÃ©es (ETL)**
- [x] SchÃ©ma SQL initial & Contraintes
- [x] Ingestion JSON 1 (Programme)
- [x] Ingestion JSON 2 (Participants & Chevaux)
- [x] Ingestion JSON 3 (Historique complet & Performances)
- [x] Ingestion JSON 4 (Rapports & Paris)
- [x] Orchestrateur de reprise d'historique (Batch range)

**Machine Learning & Application**
- [ ] Construction du Dataset unifiÃ© (Feature Engineering)
- [ ] EntraÃ®nement des modÃ¨les (Victory & Top 3)
- [ ] API de prÃ©diction (FastAPI)
- [ ] Interface Web de visualisation
